

<!DOCTYPE html>
<html lang="ZH-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="yhchen">
  <meta name="keywords" content="">
  
    <meta name="description" content="Kimi1.5 采取的训练流程:  graph LR     A[预训练阶段] --&gt; B[普通SFT]     B --&gt; C[Long-CoT SFT]     C --&gt; D[强化学习]     D --&gt; E[Long2short 优化]          A:::pretrain     B:::sft     C:::longcot     D:::rl">
<meta property="og:type" content="article">
<meta property="og:title" content="kimi1.5 technical report">
<meta property="og:url" content="http://example.com/2025/03/22/kimi1-5-technical-report/index.html">
<meta property="og:site_name" content="yhchen&#39;s blog">
<meta property="og:description" content="Kimi1.5 采取的训练流程:  graph LR     A[预训练阶段] --&gt; B[普通SFT]     B --&gt; C[Long-CoT SFT]     C --&gt; D[强化学习]     D --&gt; E[Long2short 优化]          A:::pretrain     B:::sft     C:::longcot     D:::rl">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-03-22T08:36:07.000Z">
<meta property="article:modified_time" content="2025-03-22T09:11:15.327Z">
<meta property="article:author" content="yhchen">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>kimi1.5 technical report - yhchen&#39;s blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Startseite</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archiv</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Kategorien</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Schlagwörter</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>Über</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="kimi1.5 technical report"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-03-22 16:36" pubdate>
          2025年3月22日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          3.8k wörter
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          32 minuten
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">kimi1.5 technical report</h1>
            
            
              <div class="markdown-body">
                
                <p><strong>Kimi1.5 采取的训练流程</strong>: </p>
<pre><code class=" mermaid">graph LR
    A[预训练阶段] --&gt; B[普通SFT]
    B --&gt; C[Long-CoT SFT]
    C --&gt; D[强化学习]
    D --&gt; E[Long2short 优化]
    
    A:::pretrain
    B:::sft
    C:::longcot
    D:::rl
    E:::long2short
    
    classDef pretrain fill:#4CAF50,color:white
    classDef sft fill:#2196F3,color:white
    classDef longcot fill:#FF9800,color:white
    classDef rl fill:#9C27B0,color:white
    classDef long2short fill:#FF5722,color:white
    
    click A callback &quot;预训练阶段：多模态数据训练基础能力&quot;
    click B callback &quot;普通SFT：基础指令对齐&quot;
    click C callback &quot;Long-CoT SFT：长文本推理能力强化&quot;
    click D callback &quot;强化学习：优化生成策略&quot;
    click E callback &quot;Long2short：长文本到短文本的转换训练&quot;
</code></pre>

<hr>
<blockquote>
<p>[!tip] 原论文<br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.12599">Kimi k1.5: Scaling Reinforcement Learning with LLMs</a></p>
</blockquote>
<h2 id="1-预训练阶段的一些细节"><a href="#1-预训练阶段的一些细节" class="headerlink" title="1. 预训练阶段的一些细节"></a>1. 预训练阶段的一些细节</h2><p>Kimi的预训练阶段包含&#x3D;&#x3D;<strong>三个阶段</strong>&#x3D;&#x3D;，结合多模态数据（文本、视觉、OCR等）进行分阶段训练:</p>
<ol>
<li><p><strong>视觉-语言预训练阶段</strong><br>建立语言基础能力并逐步融合多模态数据，通过文本与视觉信息的联合训练提升跨模态理解能力</p>
</li>
<li><p><strong>冷启动阶段（冷却阶段）</strong><br>通过模型融合（Model Fusion）等技术优化模型性能，可能涉及对初始预训练模型的参数调整或架构改进</p>
</li>
<li><p><strong>长文本激活阶段</strong><br>在预训练后期引入长文本数据集（如扩展至128K上下文长度），增强模型对长文本的理解和生成能力。此阶段通过严格的数据质量控制，确保训练数据的相关性、多样性及平衡性</p>
</li>
</ol>
<blockquote>
<p>[!NOTE]<br>冷却阶段(退火阶段)</p>
<ol>
<li><strong>能力巩固</strong></li>
</ol>
<ul>
<li>在初始的Vision-language预训练后，模型已具备基础的多模态理解能力。Cooldown阶段通过<strong>精选数据（curated data）​</strong>和<strong>合成数据（synthetic data）​</strong>，进一步强化模型在需要逻辑推理（如数学、代码）和知识处理（如事实性问答）任务上的表现。</li>
<li>例如，可能针对数学问题生成更多变体，或通过知识图谱增强事实性问答的训练数据。</li>
</ul>
<hr>
<ol start="2">
<li><strong>数据优化</strong></li>
</ol>
<ul>
<li><strong>精选数据</strong>：选择高质量、高难度的样本（如竞赛题目、专业领域问题），提升模型处理复杂问题的能力。</li>
<li><strong>合成数据</strong> ：利用规则或生成模型（如自动生成代码测试用例、数学证明步骤）创建针对性数据，填补真实数据中的不足，增强泛化性。</li>
</ul>
<hr>
<ol start="3">
<li><strong>过渡到长上下文训练</strong>：</li>
</ol>
<ul>
<li>在进入<strong>Long-context activation</strong>​（支持128k tokens的上下文）前，cooldown阶段确保模型在<strong>短上下文任务中足够鲁棒</strong>。例如:<ul>
<li>解决数学题时，模型需精准定位关键步骤，避免长上下文中的干扰。</li>
<li>处理知识问答时，快速检索相关信息，减少冗余推理</li>
</ul>
</li>
</ul>
<hr>
<ol start="4">
<li><strong>训练策略调整</strong></li>
</ol>
<ul>
<li>可能降低学习率或调整优化器参数，避免预训练后的性能震荡</li>
<li>采用课程学习（Curriculum Learning），从简单任务逐步过渡到复杂任务，平衡模型的学习曲线</li>
</ul>
</blockquote>
<p><strong>对比其他阶段</strong>：</p>
<ul>
<li>​<strong>预训练（Vision-language）​</strong>：广泛学习语言和多模态关联（如图文匹配）。</li>
<li>​<strong>Cooldown</strong>：针对性强化推理和知识任务，类似“专项特训”。</li>
<li>​<strong>Long-context activation</strong>：扩展上下文容量，适配长文本&#x2F;多模态输入（如整本书分析、复杂流程图解析）。<blockquote>
<p>并且 long-context activation 这一步是渐进拓展的，4k -&gt; 32k -&gt; 128k (原文提到)</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>[!warning]<br>需要注意的是！<br>Cooldown 阶段可不是 SFT哦！(<strong>而是针对性预训练</strong>)</p>
<p>在论文的附录B中有介绍到，这里的阶段还是 pre-train，因为训练目标任务仍然是 NTP (next token prediction)</p>
</blockquote>
<table>
<thead>
<tr>
<th><strong>维度</strong></th>
<th>​<strong>Cooldown阶段</strong></th>
<th>​<strong>监督微调（SFT）​</strong></th>
</tr>
</thead>
<tbody><tr>
<td>​<strong>主要目标</strong></td>
<td>​<strong>巩固多模态能力</strong>​（推理、知识、跨模态对齐）</td>
<td>​<strong>适应特定任务</strong>​（如对话、分类、生成）</td>
</tr>
<tr>
<td>​<strong>数据性质</strong></td>
<td>混合使用<strong>精选数据（高难度任务）​</strong>与<strong>合成数据</strong></td>
<td>主要依赖<strong>人工标注的高质量任务数据</strong>​（如问答对）</td>
</tr>
<tr>
<td>​<strong>训练范围</strong></td>
<td>覆盖<strong>多任务、多领域</strong>​（如数学、代码、事实问答）</td>
<td>聚焦<strong>单一任务或垂直领域</strong>​（如客服对话）</td>
</tr>
<tr>
<td>​<strong>优化策略</strong></td>
<td>可能调整学习率、优化器，但<strong>不显著改变模型架构</strong></td>
<td>可能修改损失函数或添加任务头（如分类器）</td>
</tr>
</tbody></table>
<ul>
<li><p><strong>Cooldown</strong>更接近<strong>通用能力的预训练延伸</strong>，而<strong>SFT</strong>是<strong>任务导向的最终适配</strong>。</p>
</li>
<li><p>如果cooldown阶段大量使用人工标注的监督数据，则可视为<strong>广义的SFT</strong>；但若以合成&#x2F;弱监督数据为主，则与SFT有本质区别。</p>
</li>
<li><p>&#x3D;&#x3D;实际论文中需结合具体实现判断&#x3D;&#x3D;，但核心差异在于<strong>是否以任务性能为直接优化目标</strong>。</p>
</li>
</ul>
<hr>
<h2 id="2-普通SFT阶段的细节"><a href="#2-普通SFT阶段的细节" class="headerlink" title="2. 普通SFT阶段的细节"></a>2. 普通SFT阶段的细节</h2><blockquote>
<p>[!NOTE]<br>数据集大小：100w</p>
</blockquote>
<p><strong>训练细节：</strong></p>
<ol>
<li>epoch 1用的32k，后面的epoch全是128k （不用连续多几个epoch训练32吗？）</li>
<li>epoch 1学习率从2 × 10⁻⁵下降到2 × 10⁻⁶, 后面是重新预热到1 × 10⁻⁵，最后下降到1 × 10⁻⁶</li>
</ol>
<blockquote>
<p>这种策略被称为 <strong>增加上下文长度的训练（Increasing Context Length Training）</strong> 或者叫**课程学习（Curriculum Learning）</p>
</blockquote>
<hr>
<h2 id="3-Long-CoT-SFT-部分细节"><a href="#3-Long-CoT-SFT-部分细节" class="headerlink" title="3. Long-CoT SFT 部分细节"></a>3. Long-CoT SFT 部分细节</h2><blockquote>
<p>[!tip]<br>前提<br>构建 高质量 强化学习prompt 对模型推理效果非常好, 可以避免奖励作弊（reward hacking）和过拟合</p>
<ol>
<li><strong>多样性覆盖</strong>:</li>
</ol>
<ul>
<li><strong>领域广泛性</strong> ：涵盖STEM、编程、通用推理等多学科，支持跨领域适应性</li>
<li><strong>数据来源</strong> ：整合竞赛题目、文本和图文问答数据，通过自动过滤筛选需复杂推理且易验证的问题。</li>
<li><strong>标签系统</strong> ：按学科和领域分类，确保均衡分布（如引用文献中的分类方法）</li>
</ul>
<ol>
<li><strong>难度平衡</strong>(&#x3D;&#x3D;重要&#x3D;&#x3D;)</li>
</ol>
<ul>
<li><strong>动态评估</strong> ：利用SFT模型对提示的难度进行自适应评估, 通过率低代表难度越高</li>
<li><strong>分级分布</strong> ：混合简单、中等、困难问题，避免模型过度依赖特定难度。(类似课程学习)</li>
</ul>
<ol>
<li><strong>可验证性</strong>（&#x3D;&#x3D;重要&#x3D;&#x3D;）</li>
</ol>
<ul>
<li><strong>排除易攻击问题</strong> ：移除选择题、判断题、证明题等易通过猜测或错误推理蒙混过关的题型。</li>
<li><strong>反奖励黑客策略</strong>：要求模型在无推理链（CoT）的情况下尝试回答，若在N次尝试内猜中答案（N&#x3D;8），则剔除该prompt （<em>说明这个问题很简单，不需要推理，不利于这种策略训练</em>）</li>
</ul>
</blockquote>
<p><strong>Long-CoT SFT的核心目标:</strong></p>
<p>通过构建高质量的“长链推理”（Long-CoT）数据集，提升模型生成逻辑连贯、细节丰富的推理过程的能力。</p>
<p><strong>怎么做</strong>：  </p>
<ol>
<li><p><strong>数据集设计</strong>：  </p>
<ul>
<li>用筛选后的高质量问题，搭配<strong>人工验证的完整推理路径</strong>（类似“一步步解题的参考答案”）。  </li>
<li>包含文本和图文混合的问题，覆盖多种推理类型（如数学、代码、常识）。</li>
</ul>
</li>
<li><p><strong>训练方法</strong>：  </p>
<ul>
<li><strong>轻量微调</strong>：在小而精的数据集上训练模型，重点学习如何：  <ul>
<li><strong>分步骤规划</strong>（先想好怎么解题再动手）；  </li>
<li><strong>检查中间步骤</strong>（及时发现错误）；  </li>
<li><strong>尝试不同解法</strong>（灵活调整思路）。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>效果</strong>：模型回答更像人类思考——<strong>逻辑连贯、细节丰富</strong>，尤其在复杂任务（如长文本生成、多步骤推理）中表现更好。  </p>
<p><strong>一句话总结</strong>：用“一步步教模型怎么想”的数据集，让它学会像人一样详细、严谨地解决问题。</p>
<hr>
<h2 id="4-强化学习的部分细节"><a href="#4-强化学习的部分细节" class="headerlink" title="4.强化学习的部分细节"></a>4.强化学习的部分细节</h2><h3 id="4-1-数据集构造"><a href="#4-1-数据集构造" class="headerlink" title="4.1 数据集构造"></a>4.1 数据集构造</h3><p>(第3部分讲了一点，就是Long-CoT SFT的前提)</p>
<hr>
<h3 id="4-2-问题设定"><a href="#4-2-问题设定" class="headerlink" title="4.2 问题设定:"></a>4.2 问题设定:</h3><p><strong>优化目标函数</strong>:<br>$$\max_\theta\mathbb{E}<em>{(x,y^*)\thicksim\mathcal{D},(y,z)\thicksim\pi</em>\theta}\left[r(x,y,y^*)\right]\mathrm{~.}$$</p>
<blockquote>
<p>[!tip]<br><strong>核心要点解释</strong>: </p>
<ol>
<li><strong>方法</strong>：用强化学习（RL）训练模型生成<strong>思维链（CoT）</strong>，通过奖励机制优化策略。</li>
<li><strong>奖励设计</strong>：</li>
</ol>
<ul>
<li><strong>可验证问题</strong>（如编程）：奖励由预定义规则决定（如测试用例是否通过）</li>
<li><strong>自由形式问题</strong>（如开放问答）：训练一个<strong>奖励模型</strong>  $r(x, y, y^<em>)$ ，预测答案 $y$ 是否与真实值 $y^</em>$ 匹配（输出0&#x2F;1, &#x3D;&#x3D;即奖励模型是一个二分类模型&#x3D;&#x3D;）</li>
</ul>
<ol>
<li><strong>生成过程</strong>：</li>
</ol>
<ul>
<li>给定问题 $x$ ，模型 $\pi_\theta$ 生成CoT（ $z$ ）和最终答案（ $y$ ），即：$$z \sim \pi_\theta(\cdot|x), y \sim \pi_\theta(\cdot|x, z)$$</li>
</ul>
<ol>
<li><strong>评估标准</strong>：CoT的质量取决于其能否推导出正确答案（奖励值为1）</li>
<li><strong>优化目标</strong>：最大化模型生成的CoT和答案的期望奖励，以提升策略 $\pi_\theta$ 。</li>
</ol>
<p>注意：<br><strong>策略 $\pi_\theta$</strong> : 控制生成过程的参数化模型</p>
</blockquote>
<p><strong>优化策略</strong>：</p>
<p>一种基于 <strong>在线策略镜像下降（Online Policy Mirror Descent）</strong> 的训练算法，用于解决强化学习或序列决策问题。<br>$$\max_\theta\mathbb{E}<em>{(x,y^*)\thicksim\mathcal{D}}\left[\mathbb{E}</em>{(y,z)\thicksim\pi_\theta}\left[r(x,y,y^*)\right]-\tau\mathrm{KL}(\pi_\theta(x)||\pi_{\theta_i}(x))\right]$$</p>
<blockquote>
<p>[!tip]<br>其中:</p>
<ul>
<li>$\mathcal{D}$  是数据分布，表示输入 $x$  和目标  $y^*$  的联合分布。</li>
<li>$r(x, y, y^<em>)$  是奖励函数，衡量策略  $\pi_\theta$  的输出  $(y, z)$  与目标  $y^</em>$  的匹配程度。</li>
<li>$\text{KL}(\pi_\theta(x) | \pi_{\theta_i}(x))$  是策略  $\pi_\theta$  和参考策略  $\pi_{\theta_i}$  的 <strong>KL散度</strong>，用于控制新策略与旧策略之间的差异。</li>
<li>$\tau &gt; 0$  是正则化参数，控制 KL 正则项的强度。</li>
</ul>
</blockquote>
<p><strong>目标函数的意义</strong>：</p>
<ul>
<li>第一项  $\mathbb{E}<em>{(y, z) \sim \pi</em>\theta} \left[ r(x, y, y^*) \right]$  表示在当前策略下期望的奖励。</li>
<li>第二项  $\tau \text{KL}(\pi_\theta(x) | \pi_{\theta_i}(x))$  是正则化项，确保新策略不会偏离参考策略太多，从而保持策略的稳定性。<blockquote>
<p>跟DPO等强化学习类似, 都是奖励函数 + 一个KL散度（约束奖励函数）</p>
</blockquote>
</li>
</ul>
<p>这时候，根据优化策略的 <strong>闭式解(Closed-form Solution)</strong> 如下:<br>$$\pi^<em>(y, z | x) &#x3D; \pi_{\theta_i}(y, z | x) \exp(r(x, y, y^</em>) &#x2F; \tau) &#x2F; Z$$</p>
<blockquote>
<p>[!tip]<br>其中：</p>
<ul>
<li>$Z &#x3D; \sum_{y’, z’} \pi_{\theta_i}(y’, z’ | x) \exp(r(x, y’, y^<em>) &#x2F; \tau)$  是归一化因子，确保  $\pi^</em>(y, z | x)$  是一个有效的概率分布。</li>
</ul>
<p><strong>归一化因子的作用</strong>: 归一化因子 $Z$  确保策略的概率分布性质，即所有可能的  $(y, z)$  的概率之和为 1</p>
<p>$^*$ <strong>闭式解</strong>就是可以通过数学推导直接得到的显式解</p>
</blockquote>
<p>通过对上式取对数（<em>非常容易推导，不要被吓到了</em>），可以得到以下约束：<br>$$r(x, y, y^<em>) - \tau \log Z &#x3D; \tau \log \frac{\pi^</em>(y, z | x)}{\pi_{\theta_i}(y, z | x)}.$$</p>
<p>这一约束允许在优化过程中利用 <strong>离线数据（off-policy data）</strong>，因为  $\pi^<em>$  的形式可以直接从*<em>参考策略</em></em>  $\pi_{\theta_i}$  和<strong>奖励</strong>  $r(x, y, y^*)$  推导出来。</p>
<blockquote>
<p>off-policy data 是相对 on-policy data而言，</p>
<ul>
<li>on-policy data是智能体通过<strong>当前策略与环境实时交互生成数据</strong>，并立即用于更新策略（例如 SARSA）；</li>
<li>off-policy data 是智能体使用<strong>预先收集的、由其他策略生成的历史数据</strong>进行训练（例如 Q-Learning、DQN）。</li>
</ul>
</blockquote>
<p><strong>损失函数</strong>：<br>根据上述约束，定义替代损失函数（surrogate loss）：</p>
<p>$$L(\theta) &#x3D; \mathbb{E}<em>{(x, y^*) \sim \mathcal{D}} \left[ \mathbb{E}</em>{(y, z) \sim \pi_{\theta_i}} \left[ \left( r(x, y, y^*) - \tau \log Z - \tau \log \frac{\pi_\theta(y, z | x)}{\pi_{\theta_i}(y, z | x)} \right)^2 \right] \right]$$</p>
<p>这一损失函数的目标是使<strong>当前策略</strong>  $\pi_\theta$  尽可能接近<strong>最优策略</strong>  $\pi^*$ ，同时考虑奖励和正则化项。</p>
<p>由于  $\tau \log Z$  难以直接计算，可以通过<strong>采样近似</strong>：</p>
<p>$$\tau \log Z \approx \tau \log \frac{1}{k} \sum_{j&#x3D;1}^k \exp(r(x, y_j, y^*) &#x2F; \tau)$$</p>
<p>其中  $(y_1, z_1), \ldots, (y_k, z_k) \sim \pi_{\theta_i}$ 是从参考策略  $\pi_{\theta_i}$  中采样的样本。</p>
<p>此外，还可以用采样奖励的均值  $\bar{r} &#x3D; \text{mean}(r(x, y_1, y^<em>), \ldots, r(x, y_k, y^</em>))$  来进一步简化计算，这种方法在实践中效果良好。</p>
<p>最终，通过<strong>梯度下降优化</strong>替代损失函数  $L(\theta)$ 。对于每个问题  $x$ ，从参考策略  $\pi_{\theta_i}$  中采样  $k$  个响应  $(y_j, z_j)$ ，梯度公式为：</p>
<p>$$\frac{1}{k} \sum_{j&#x3D;1}^k \left( \nabla_\theta \log \pi_\theta(y_j, z_j | x) (r(x, y_j, y^*) - \bar{r}) - \frac{\tau}{2} \nabla_\theta \left( \log \frac{\pi_\theta(y_j, z_j | x)}{\pi_{\theta_i}(y_j, z_j | x)} \right)^2 \right)$$</p>
<blockquote>
<p>[!tip]<br><strong>梯度项的意义</strong></p>
<ul>
<li>第一项  $\nabla_\theta \log \pi_\theta(y_j, z_j | x) (r(x, y_j, y^*) - \bar{r})$  是奖励驱动的更新，鼓励策略向高奖励的方向调整。</li>
<li>第二项  $\frac{\tau}{2} \nabla_\theta \left( \log \frac{\pi_\theta(y_j, z_j | x)}{\pi_{\theta_i}(y_j, z_j | x)} \right)^2$  是正则化项，确保新策略不偏离参考策略太多。(&#x3D;&#x3D;用平方是因为可以更敏感， L2正则化?&#x3D;&#x3D;)</li>
</ul>
</blockquote>
<hr>
<h2 id="附录：4-2中闭式解推导"><a href="#附录：4-2中闭式解推导" class="headerlink" title="附录：4.2中闭式解推导"></a>附录：4.2中闭式解推导</h2><p>目标是找到一个策略 $\pi^<em>$，在给定参考策略 $\pi_{\theta_i}$ 的情况下，最大化期望奖励的同时限制策略变化幅度。<br>$$\max_{\pi} \mathbb{E}_{(x, y^</em>) \sim \mathcal{D}} \left[ \mathbb{E}<em>{(y, z) \sim \pi(\cdot|x)} \left[ r(x, y, y^*) \right] - \tau \cdot \text{KL}(\pi(\cdot|x) | \pi</em>{\theta_i}(\cdot|x)) \right] \tag{1}$$</p>
<p>根据 KL散度定义:<br>$$\text{KL}(\pi | \pi_{\theta_i}) &#x3D; \mathbb{E}<em>{(y, z) \sim \pi} \left[ \log \frac{\pi(y, z|x)}{\pi</em>{\theta_i}(y, z|x)} \right] \tag{2}$$</p>
<p>把 （2）带入 （1）中，结果如下:<br>$$\max_{\pi} \mathbb{E}<em>{(x, y^*) \sim \mathcal{D}} \left[ \mathbb{E}</em>{(y, z) \sim \pi} \left[ r(x, y, y^*) - \tau \log \frac{\pi(y, z|x)}{\pi_{\theta_i}(y, z|x)} \right] \right] \tag{3}$$</p>
<p>把（3）中的期望展开，再加上对数：<br>$$\max_{\pi} \mathbb{E}<em>{x, y^*} \left[ \sum</em>{y, z} \pi(y, z|x) \left( r(x, y, y^<em>) - \tau \log \pi(y, z|x) + \tau \log \pi_{\theta_i}(y, z|x) \right) \right] \tag{4}$$<br>提取公因式进一步整理：<br>$$\max_{\pi} \mathbb{E}_{x, y^</em>} \left[ \sum_{y, z} \pi(y, z|x) \cdot \left( \frac{r(x, y, y^*)}{\tau} + \log \pi_{\theta_i}(y, z|x) - \log \pi(y, z|x) \right) \right] \cdot \tau \tag{5}$$</p>
<p>由于 $\pi(\cdot|x)$ 是概率分布，需满足归一化约束：</p>
<p>$$\sum_{y, z} \pi(y, z|x) &#x3D; 1$$</p>
<p>引入拉格朗日乘子 $\lambda$，构造拉格朗日函数：</p>
<p>$$\mathcal{L}(\pi, \lambda) &#x3D; \mathbb{E}<em>{x, y^*} \left[ \sum</em>{y, z} \pi(y, z|x) \left( \frac{r(x, y, y^*)}{\tau} + \log \pi_{\theta_i}(y, z|x) - \log \pi(y, z|x) \right) \right] \cdot \tau - \lambda \left( \sum_{y, z} \pi(y, z|x) - 1 \right) \tag{6}$$</p>
<p>接下来就是拉格朗日乘数法的标准解法，先求导，再领导数为0，就可以得到解（<em>DNA动了吗</em>）。<br>对 $\pi(y, z|x)$ 求导，令导数为零：</p>
<p>$$\frac{\partial \mathcal{L}}{\partial \pi(y, z|x)} &#x3D; \left( \frac{r(x, y, y^*)}{\tau} + \log \pi_{\theta_i}(y, z|x) - \log \pi(y, z|x) - 1 \right) \cdot \tau - \lambda &#x3D; 0 \tag{7}$$</p>
<p>整理后得到：<br>$$\log \pi(y, z|x) &#x3D; \frac{r(x, y, y^*)}{\tau} + \log \pi_{\theta_i}(y, z|x) - \frac{\lambda}{\tau} - 1 \tag{8}$$</p>
<p>对两边取 $e$ 为底的指数：</p>
<p>$$\pi(y, z|x) &#x3D; \pi_{\theta_i}(y, z|x) \cdot \exp\left( \frac{r(x, y, y^*)}{\tau} - \frac{\lambda}{\tau} - 1 \right) \tag{9}$$</p>
<p>利用归一化约束 $\sum_{y, z} \pi(y, z|x) &#x3D; 1$，定义归一化因子 $Z$：</p>
<p>$$Z &#x3D; \exp\left( \frac{\lambda}{\tau} + 1 \right) &#x3D; \sum_{y’, z’} \pi_{\theta_i}(y’, z’|x) \exp\left( \frac{r(x, y’, y^*)}{\tau} \right)\tag{10}$$</p>
<p>最终得到闭式解：</p>
<p>$$\pi^<em>(y, z|x) &#x3D; \frac{\pi_{\theta_i}(y, z|x) \exp\left( \frac{r(x, y, y^</em>)}{\tau} \right)}{Z} \tag{11}$$</p>
<p>证明完毕。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>kimi1.5 technical report</div>
      <div>http://example.com/2025/03/22/kimi1-5-technical-report/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Beitragsautor</div>
          <div>yhchen</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Veröffentlicht am</div>
          <div>2025年3月22日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Urheberrechtshinweis</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/03/22/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/" title="测试文章">
                        <span class="hidden-mobile">测试文章</span>
                        <span class="visible-mobile">Nächster</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Inhaltsverzeichnis</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Suchen</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Stichwort</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog funktioniert am besten mit aktiviertem JavaScript</div>
  </noscript>
</body>
</html>
